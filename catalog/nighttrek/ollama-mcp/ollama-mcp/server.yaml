identifier: nighttrek/ollama-mcp/ollama-mcp
repo:
  provider: github.com
  url: https://github.com/NightTrek/Ollama-mcp
  name: Ollama-mcp
  owner: NightTrek
server:
  subdirectory: /
  name: Ollama MCP Server
  description: Integrate Ollama's local LLM capabilities into your applications
    seamlessly. Access a full range of Ollama functionalities through a clean
    MCP interface, enabling model management and execution with ease. Enjoy the
    benefits of running AI models locally while maintaining control and privacy.
  flags:
    isOfficial: false
    isCommunity: true
    isHostable: true
